import { ChatWindow } from "@/components/ChatWindow";

export default function Home() {
  const InfoCard = (
    <div className="p-4 md:p-8 rounded bg-[#25252d] w-full max-h-[85%] overflow-hidden">
      <h1 className="text-3xl md:text-4xl mb-4">
        â–² Next.js + LangChain.js ğŸ¦œğŸ”—
      </h1>
      <ul>
        <li className="text-l">
          ğŸ¤
          <span className="ml-2">
            I&apos;m just playing around with {" "} 
            <a href="https://js.langchain.com/" target="_blank">
              LangChain.js
            </a>{" "}
            and the Vercel{" "}
            <a href="https://sdk.vercel.ai/docs" target="_blank">
              AI SDK
            </a>{" "}
            in a{" "}
            <a href="https://nextjs.org/" target="_blank">
              Next.js
            </a>{" "}
            project.  It is pretty fresh.
          </span>
        </li>
        <li className="hidden text-l md:block">
          ğŸ’»
          <span className="ml-2">
            You can find the prompt and model logic for this use-case in{" "}
            <code>app/api/chat/route.ts</code>.
          </span>
        </li>
        <li className="hidden text-l md:block">
          ğŸ¨
          <span className="ml-2">
            The main frontend logic is found in <code>app/page.tsx</code>.
          </span>
        </li>
      </ul>
    </div>
  );
  return (
    <ChatWindow
      endpoint="api/chat"
      emoji="ğŸ´â€â˜ ï¸"
      titleText="My Helpful ML Buddy"
      placeholder="I&apos;an LLM who is here to help you with your AI/ML problems!  Ask away!"
      emptyStateComponent={InfoCard}
    ></ChatWindow>
  );
}
